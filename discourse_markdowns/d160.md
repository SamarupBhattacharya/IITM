facing same error, have you fouind any solution?
sir for this task- A6 Find all Markdown ( .md ) files in /data/docs/ . For each file, extract the first occurrance of each H1 (i.e. a line starting with # ). Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title (e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...} )   ‚Ä¶I am getting correct result for all files but for the very first file budget.md it shows wrong. my result- { ‚Äúbudget.md‚Äù: ‚ÄúSuccess easy same main modern doctor.‚Äù, ‚Äúbuild.md‚Äù: ‚ÄúShoulder follow own never above.‚Äù, and in the data files there is different heading in budget.md.-  # Series dog who make specific agree between. my question is this if it works for all the files then why not for this file budget.md @Saransh_Saini @Jivraj @carlton
do you able to do this task * A5 . Write the first line of the 10 most recent .log file in /data/logs/ to /data/logs-recent.txt , most recent first ‚Ä¶ i am also doing using prompt no hard-coded.
yes doing this only but finding correct for most of the files.
yes i am able to do task a5.
so you directly using prompt for doing this task.
yes i am only using prompt based method
If filename has number in its name then extract the number from the filename and convert it to an integer before sorting .Ensure numbers inside filenames are compared as integers, not as strings, to maintain proper order. Sort filenames in said in task. Avoid any lexicographical sorting issues.    i am using this extra info for doing this but still it does not give accurate result. can you help me in this
i already shared my repo u can check there.
you have pushed data,datagen and evaluate files‚Ä¶do we have to submit them as well?? (also send the docker file)
Check the file once, there is a possibility that it‚Äôs either fetching a comment or the second heading. Refactor your prompt to search only for the First Heading, specify it explixitly.
okay let me check once. one more thing sir {‚Äúfirst_name‚Äù: ‚ÄúCrystal‚Äù, ‚Äúlast_name‚Äù: ‚ÄúWilson‚Äù, ‚Äúemail‚Äù: ‚Äú delgadorebecca@example.com ‚Äù}   then what will be the sorted-contact for this as in email there is no first and lastname present. @Saransh_Saini
Hey, I submitted the project links in the google form yesterday but, today in the portal it shows that I have not submitted the project.
I am getting this error while running evaluate.py on task A9 HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

üî¥ A9 failed: 'data' There were no authentication issues till yesterday. please guide @carlton @Jivraj @Saransh_Saini
This is happening because evaluate.py is unable to fetch your API Key from the environment variables. Create a new variable and set it‚Äôs value to your API Key then try.
Hi everyone, I‚Äôm running into an issue with the AI Proxy embeddings endpoint while executing the A9 task. Every time I send a POST request to: bash Copy https://aiproxy.sanand.workers.dev/openai/v1/embeddings I receive a 401 Unauthorized response. This, in turn, causes my code to fail with a KeyError: 'data' because the expected JSON response doesn‚Äôt include the "data" key. What I‚Äôve Tried Token Verification: I‚Äôm using the AIPROXY_TOKEN obtained by logging in at aiproxy.sanand.workers.dev with my IITM email. The token is passed in the header as follows: python Copy "Authorization": f"Bearer {AIPROXY_TOKEN}" I added debug prints to confirm that the token is being used correctly (printing the first few characters). API Request Details: The request includes the correct Content-Type: application/json header. The payload is set as: json Copy {"model": "text-embedding-3-small", "input": ["Test"]} Despite this, the response status is consistently 401 Unauthorized. Debug Output: Here‚Äôs a snippet of the debug output: bash Copy HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"
üî¥ A9 failed: 'data' This confirms that the issue is with the authentication rather than our processing logic. What I Suspect The token may be invalid, expired, or misconfigured. There could be changes in the token permissions or endpoint requirements that I‚Äôm not aware of. Alternatively, there might be an issue on the server side with token validation. Request for Help Has anyone else encountered this issue recently? Could someone verify if there are any changes to the authentication requirements for the embeddings endpoint? Any insights or updated instructions on how to ensure the token is valid and has the proper permissions would be greatly appreciated. Thanks in advance for your assistance!
B5. Run a SQL query on a SQLite or DuckDB database Should I ask for the SQL data base. Or the agent should be smart enough to find the required database‚Ä¶ Moreover in the data folder there is only one database is it should be robust to handle multiple databases‚Ä¶
same issue i also face                   pls sir help us fix this issue and provide us more  token HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings ‚ÄúHTTP/1.1 429 Too Many Requests‚Äù A9 failed: ‚Äòdata‚Äô @Jivraj @carlton @Saransh_Saini
Error: Failed to process image URL 'https://emoji.discourse-cdn.com/google/red_circle.png?v=12' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
I had a question on evaluation by the course team. To test that my application would run everywhere, I first deleted all images from my local machine using podman rmi -a and then ran podman run --rm -p 8000:8000 -e AIPROXY_TOKEN=$AIPROXY_TOKEN $IMAGE_NAME with the appropriate variables set. This is as per the instructions provided here . But this gave me the following error: Error: short-name "freshbash/dataworks-agent" did not resolve to an alias and no unqualified-search registries are defined in "/etc/containers/registries.conf The above is the format in which we have to provide the image name in the Google form. So, I was confused whether this would succeed during actual evaluation. The only way its working right now is when I specify the image name to be docker.io/freshbash/dataworks-agent I‚Äôm not yet very good with how containers work so some insights would be very helpful. Thanks!
Nice bro, if its getting 8 you are sorted, probably get more later. But Prompting seems a little less info BUT Structured Outputs JSON Mode Outputs valid JSON Yes Yes Adheres to schema Yes (see supported schemas) No Compatible models gpt-4o-mini, gpt-4o-2024-08-06, and later gpt-3.5-turbo, gpt-4-* and gpt-4o-* models Enabling response_format: { type: json_schema, json_schema: {strict: true, schema: ‚Ä¶} } response_format: { type: json_object } try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_object"}
        ) github.com/23f2005593/tds app.py main prompt = ( f"The Python code generated for the task '{task}' produced the following error when executed:\n" f"{error_message}\n\n" f"Here is the original code:\n{original_code_data['code']}\n\n" "Please provide a corrected version of the code that fixes the error. Return only a JSON object with:\n" "- code: the corrected Python code as a string\n" "- function_name: name of the main function\n" "- required_libraries: list of required pip packages\n\n" "Make sure the code is simple, direct, and error-free this time. And try not to mess it up like before." ) try: response = client.chat.completions.create( model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}], temperature=0, response_format={"type": "json_object"} ) except Exception as exc: logger.error("Error connecting to OpenAI API for auto-fix: %s", exc) raise HTTPException(status_code=500, detail="Connection error during auto-fix. Maybe it's time to admit defeat?") you are taking a chance on that format
