by clicking the link image 1198×136 9.49 KB image 1750×581 70.9 KB I am getting this opened.
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/3/2/32bd53681054ab17de6350c49f68b405acd538b9_2_690x78.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/9/3/937562cc32dc76a582f6845678b048730622d388_2_690x229.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Hi @Divya1 , There won’t be any project1 page such as GA1s, there is a google form(which can be found in same page) which needs to be filled after you do project1.
Hi @23f2005325 , Extracting details from credit cards is sensitive, try using strong prompts or take code from LLM and execute it in script. kind regards
Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environment using maybe ollama(local llm as now there is deepseek opensource, i doubt we would need to use openai for testing, just for production(test submission)  would be enough) and also some agent(langchain, autogen, crewai) just a quick how-to on setting up and problems while setting up if possible More resources on docker. Using docker as a virtual environment. Editing and executing code in Dockerfiles (like when you change code in src a web framework automatically reloads page(hot reload)), something along the lines of this . @carlton @Jivraj
23f1002382: Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen In Tuesday’s(21 January) session we had discussed docker towards ending of session. What was discussed in that live session regarding docker: Search for existing containers on repositories such as dockerhub. Pull an existing docker image. Run that image inside a container. Enter to that container and modify something(such as installing python inside a ubuntu container, for customization or create some file) Once done you can commit it. And push customized container’s image to docker hub. Regarding local models running for project1, it’s a good idea, we will see if it’s possible to discuss in session.
Error: Failed to process image URL 'https://dub1.discourse-cdn.com/flex013/user_avatar/discourse.onlinedegree.iitm.ac.in/23f1002382/48/68945_2.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
In the google forms , I have 2 questions in one form now to submit should it is compulsory that to answer the both the questions?
Hi @Divya1 Screenshot 2025-01-29 at 8.19.05 am 1738×982 122 KB Please do very carefully all things mentioned in the Deliverables as well as look at the Evaluation Section. Screenshot 2025-01-29 at 8.26.08 am 1460×496 45.5 KB We had a session on 28th Jan introducing all the important aspects of Project. If you do not do everything exactly as mentioned especially the pre - requisites mentioned in the Evaluation section you will get 0 in the project and there will be no appeal for failing to meet the pre - requisites of the evaluation criteria. In order for us to evaluate the project you have to provide the deliverables mentioned above. Kind regards
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/3/5/35e7ce763c7605e99ee1fad3906e1cd31d094b31_2_690x389.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/8/9/898ab28ebe773e40fb3ad9b98c71ce4c5d063c09_2_690x234.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Subject: Request to Add Instructors to Private GitHub Repo Message: "Dear [Instructors’ Names], I’ve set up the environment and dependencies for the project and was wondering if it would be appropriate to add you to my private GitHub repository. I’d appreciate any guidance on improving performance, scalability, and design principles. Please let me know if this is feasible or if there’s a more suitable way to seek feedback. Apologies if this request is out of scope. Thank you for your time! Best, [Your Name]"* ChatGPT can make mistakes. Check important info.
@23f1002382 - You’re welcome to use the evaluation script in this post for private repos. Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub You can use this to validate your code for Project 1. 
Please note: 

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in t… For public repos submitted in the form, I’ll run this script over the weekend and share preliminary results.
Error: Failed to process image URL 'https://dub1.discourse-cdn.com/flex013/user_avatar/discourse.onlinedegree.iitm.ac.in/s.anand/48/15264_2.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
T  h  a  n  k      y  o  u         sir.
For A6, /data/docs/ has subfolders with .md files from which we have to extract the heading level 1’s (#) right? Apparently there are few files with different content but the same name. Can someone confirm the same? If yes how to address these files @Jivraj @carlton
I had set up the environment and dependencies and everything was working fine. When i tried to recreate it from scratch in a new codespace it broke. I fixed almost everything except this error @ANdIeCOOl ➜ /workspaces/TDS-Project-1 (main) $ crewai create crew b2b
Traceback (most recent call last):
  File "/home/codespace/.python/current/bin/crewai", line 5, in <module>
    from crewai.cli.cli import crewai
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/__init__.py", line 3, in <module>
    from crewai.agent import Agent
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agent.py", line 7, in <module>
    from crewai.agents import CacheHandler
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/__init__.py", line 2, in <module>
    from .parser import CrewAgentParser
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/parser.py", line 6, in <module>
    from crewai.utilities import I18N
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/__init__.py", line 13, in <module>
    from .embedding_configurator import EmbeddingConfigurator
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/embedding_configurator.py", line 4, in <module>
    from chromadb import Documents, EmbeddingFunction, Embeddings
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/__init__.py", line 6, in <module>
    from chromadb.auth.token_authn import TokenTransportHeader
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/auth/token_authn/__init__.py", line 24, in <module>
    from chromadb.telemetry.opentelemetry import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py", line 13, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/__init__.py", line 25, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.exporter import (  # noqa: F401
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py", line 72, in <module>
    from opentelemetry.sdk.metrics.export import MetricsData
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/__init__.py", line 16, in <module>
    from opentelemetry.sdk.metrics._internal import Meter, MeterProvider
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/__init__.py", line 56, in <module>
    from opentelemetry.sdk.metrics._internal.measurement_consumer import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/measurement_consumer.py", line 29, in <module>
    from opentelemetry.sdk.metrics._internal.metric_reader_storage import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/metric_reader_storage.py", line 26, in <module>
    from opentelemetry.sdk.metrics._internal._view_instrument_match import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/_view_instrument_match.py", line 22, in <module>
    from opentelemetry.sdk.metrics._internal.aggregation import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/aggregation.py", line 48, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.exponent_mapping import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/exponent_mapping.py", line 25, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.ieee_754 import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.py", line 15, in <module>
    from ctypes import c_double, c_uint64
  File "/usr/local/python/3.12.1/lib/python3.12/ctypes/__init__.py", line 8, in <module>
    from _ctypes import Union, Structure, Array
ImportError: /usr/local/python/3.12.1/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0 i updated the libffi package using sudo but while breaking something else can someone pls help me? @carlton @Jivraj @s.anand history of commands in new codespace 1  crewai --version
    2  pip install crewai crewai-tools
    3  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    4  export PATH=/opt/conda/bin:$PATH
    5  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    6  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    7  crewai create crew <project_name>
    8  crewai create crew b2b
    9  history UPDATE: IT’s WORKING if you do this in order 1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    2  export PATH=/opt/conda/bin:$PATH
    3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    5  pip install --no-cache-dir --force-reinstall typing_extensions pydantic crewai crewai-tools
    6  conda install -c conda-forge typing_extensions
    7  exec bash
    8  crewai create crew "Project 1 - LLM-based Automation Agent" Something about different environment conda and python can the instructors please help me understand it(resources ), so i can trouble shoot this later with better accuracy come precision
evaluate.py TDS course repo github.com tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ·... Contribute to sanand0/tools-in-data-science-public development by creating an account on GitHub. line 20 from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
) but we get datagen.py only in a1 task line 69 async def a1(email: str, **kwargs):
    await run(
        f"""
Install `uv` (if required) and run the script `https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py`
with `{email}` as the only argument
"""
    )
    return email in await read("/data/format.md") The issue is importing datagen before ensuring it exists just checking @carlton @Jivraj
Image URL 'https://github.githubassets.com/favicons/favicon.svg' has an unsupported MIME type ('image/svg+xml'). Skipping explanation.
Hi @23f1002382 , Yes datagen.py must be present in same directory from where you  are executing evaluate.py. Oh, You trying to use crewai locally for Project1 kind regards
Hi @JoelJeffrey , Filepath is unique for every file, which needs to be inserted to json file.
Ok. So just to confirm, since there are files with the same name, the json file should map the filepath and not the filename to the title right? Screenshot from 2025-01-31 12-25-29 790×117 19.9 KB
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/original/3X/d/3/d3ebea3238860bad920a47ff55ac33cb02ad2d63.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
no crewai, it takes really long i put time out for 300 secs(in run(task:str) in evaluate.py) still sometimes its not enough. I’ll try with autogen next and then langchain
INFO:     127.0.0.1:65085 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
data/format.md 81ms
INFO:     127.0.0.1:65149 - "POST /run?task=%0AFormat+the+contents+of+%60%2Fdata%2Fformat.md%60+using+%60prettier%403.4.2%60%2C+updating+the+file+in-place%0A HTTP/1.1" 200 OK
INFO:     127.0.0.1:65251 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
INFO:     127.0.0.1:65263 - "POST /run?task=The+file+%60%2Fdata%2Fdates.txt%60+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+%60%2Fdata%2Fdates-wednesdays.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65298 - "GET /read?path=/data/dates-wednesdays.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65312 - "POST /run?task=Sort+the+array+of+contacts+in+%60%2Fdata%2Fcontacts.json%60+by+%60last_name%60%2C+then+%60first_name%60%2C+and+write+the+result+to+%60%2Fdata%2Fcontacts-sorted.json%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65350 - "GET /read?path=/data/contacts-sorted.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65361 - "POST /run?task=Write+the+first+line+of+the+10+most+recent+%60.log%60+file+in+%60%2Fdata%2Flogs%2F%60+to+%60%2Fdata%2Flogs-recent.txt%60%2C+most+recent+first HTTP/1.1" 200 OK
INFO:     127.0.0.1:65390 - "GET /read?path=/data/logs-recent.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65402 - "POST /run?task=Find+all+Markdown+%28%60.md%60%29+files+in+%60%2Fdata%2Fdocs%2F%60.%0AFor+each+file%2C+extract+the+first+occurrance+of+each+H1+%28i.e.+a+line+starting+with+%60%23+%60%29.%0ACreate+an+index+file+%60%2Fdata%2Fdocs%2Findex.json%60+that+maps+each+filename+%28without+the+%60%2Fdata%2Fdocs%2F%60+prefix%29+to+its+title%0A%28e.g.+%60%7B%22README.md%22%3A+%22Home%22%2C+%22path%2Fto%2Flarge-language-models.md%22%3A+%22Large+Language+Models%22%2C+...%7D%60%29 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65436 - "GET /read?path=/data/docs/index.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65452 - "POST /run?task=%60%2Fdata%2Fcredit_card.png%60+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+%60%2Fdata%2Fcredit-card.txt%60 HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65482 - "GET /read?path=/data/credit-card.txt HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65503 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:49154 - "GET /read?path=/data/ticket-sales-gold.txt HTTP/1.1" 200 OK result after running evaluate.py: Score: 0 / 10 why sir @Jivraj @Saransh_Saini what is the problem here?? please do a live session of complete project process with one or two tasks if possible
Error: Failed to process image URL 'https://emoji.discourse-cdn.com/google/dart.png?v=12' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Hi Guddu, We are planning several project sessions in order to show the workflow of creating a successful project. Although you are returning a 200 ok, the get request file must match the expectation. In other words after running the first task for example, has the new format.md been formatted correctly and matches the expected output. In this case you would write out the the expected variable in the evaluate.py and see if result variable matches the expected . Then you can figure out what went wrong. Kind regards
Ok sir But please try to take those sessions sooner Because it’s taking too much time for me to do any problem(plus two more courses and one oppe you know) .so I just want to build the project before deadline.
