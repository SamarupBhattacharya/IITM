You can continue to $2. Then you would need to ask for a new token.
@carlton @Jivraj please upload recording of TDS Week 5 - Session 2. Only recordings of session 1 & 3 have been uploaded.
github.com GitHub - ANdIeCOOl/TDS-Project-1 Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub. DONE WITH A TASK , you have to create DOCKER IMAGE THOUGH < HAVE ENV file with keys , check the key value pair names, an cheers guy , we all get 9 marks hopefully
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/3/b/3bfc6f97a124e61d5c97c25e6dd6c901e0262fde_2_690x344.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
For as task description like this Write the # of Thursdays in /data/extracts.txt into /data/extracts-count.txt I have given the prompt in such detail to the LLM but it is still not able to understand the task because of the “#” symbol. The task is getting truncated even before it reaches to the LLM. Can anyone help me on this because I have tried so many things to fix this but nothing seems to help.
Hi @Jivraj , @carlton sir, I have created a docker file and run the application but it’s throwing error for A2 task No such file or directory: ‘npx’ Do i need give the node install in docker file?
Hash is just another way of writing “number”
@carlton @Jivraj sir i have tried to solve the A1. when I want to check the solution we are asked for the datagen module as the evaluate.py have ’ ''from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)
''' so do we need to download the datagen.py in the local system first… Or it should be the part of the automation only…
I am getting internal server error for task A1, I have been trying for a long time. It may be possible that i have issues with my ai_proxy token thus tell how to properly set the taken.
Yes I know that but LLM does not know that # indicates number. And no prompt is fixing this issue because the task has to be passed as query parameter and by the time LLM reads the task, it is already half gone due to #.
Where to find AIProxy token from?
what if we are out of token sir how do we complete our project then?
could u share your code once i think you should explicitly try to install npx in your code
23f1002382: ANDIECOOLER2 could you help me out with q2?
Error: Failed to process image URL 'https://dub1.discourse-cdn.com/flex013/user_avatar/discourse.onlinedegree.iitm.ac.in/23f1002382/48/68945_2.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Can you tell me where to get the AIPROXY Token from and also are u able to execute docker image push command it keeps showing as an error to me
def format_with_prettier(file_path:str, prettier_version:str):
    if file_path and os.path.exists(file_path):
        print('Path exisit - will perform prettier')
        subprocess.run(["npx", f"prettier@{prettier_version}", "--write", file_path])
    else:
        raise FileNotFoundError() This is my code
this isnt also working are you sure its right?
image 1027×917 28.1 KB
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/original/3X/d/b/dbd85efd1bbce9710794cb0434a90d37a8c20a25.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
okay but in my docker image when i tried to run that in local, its asking for npx and it doesnt work
@carlton could you please give a hint as to why this isnt working
im running locally first and then will use docker when i get a 10/10 score
