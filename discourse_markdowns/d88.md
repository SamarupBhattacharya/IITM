@Jivraj @carlton sir, I have fixed my docker image issue that was causing the error. Please re-pull my docker image so that I can get score. Please consider me for re-evaluation. All the codes were correct, only issue was a glitch in the docker image.
Hello Sir, I am facing the same issue. Please look into it. Before submission, I ran my Docker file with the evaluation script to ensure it was working, and it worked fine. Kindly help me out. My roll number is 23F3004321.
Yes, something like that, My log file shows when script tries to access file it says file not found or directory not found.
Sir, I checked my evaluation log, and the error occurred because the AI proxy token limit was exceeded . I ran the evaluation script to verify, and I scored 12/20 . image 1456×765 41.6 KB image 1094×256 9.59 KB
The image shows a Flask development server running with debug mode enabled.  Several POST requests to `/run` and GET requests to `/read` result in 500 and 404 errors.  The traceback indicates an `AttributeError: 'NoneType' object has no attribute 'lower'` in `app.py`, line 22, within the `run_task` function.
The image shows a debug log indicating errors in a program. It begins with an error stating that it's "unable to open database file." Next, a GET request for a CSV file returns a 404 error, with a subsequent "B10 failed" message. Finally, a POST request to an OpenAI embeddings API is successful (200 OK), and the overall score of some process is 12/20.
Sir, my project scored 1/20, with only B1 passed. However, when I ran the evaluation script, I got 6/10 in A tasks. Is there any way this can be checked, as the project works on deployed. Kind Regards and thanks
@carlton @Jivraj Sir, This is the id of the docker image that was evaluated: 82aeb74ca739  , but i had never provided this docker image instead my image id is de8235663462 then how it get evaluated, also none of the docker image created by me has this id. My docker image was created on linux/amd64. Please, look over it @carlton , @Jivraj . Regards, S Sharmile 23f3001688
Sir the evaluated docker file ID was mentioned as  5b28fd5b25a7 in the mail sent by you but my docker file ID is 4d8c0cc34e35. I think my docker file is not evaluated properly. Kindly do check this and help me out. My reg no 24f1002633.
@carlton My docker logs shows that OSError: Cannot find resource error occurred when the data generation script tried to access font files in generation for a8. image 1485×807 37.4 KB The datagen.py script looked for Arial font in the try block and when it encountered error it went to the except block to use DejaVuSans, the Pillow default, except it encountered the same error there, which was not handled. Thus, datagen.py stopped abruptly without creating files for A9 and A10 as well. So effectively, my A9 and A10 did not get evaluated properly as it did not have the required files due to error during data generation for A8. Can you please re-evaluate by enclosing each of the data generation function calls in their own try-except blocks? image 302×252 3.45 KB I think it would be better to enclose each of these function calls in their own try-except blocks. This screenshot is taken from the datagen.py file sent in yesterday’s results mail. So, will it be possible to re-evaluate my task A1, A8, A9 and A10? At least A9 and A10 did not even get the files to work on as they weren’t even created due to insufficient error handling in datagen.py . Also, can you help me to identify the cause of even the Pillow default font not being available? I don’t understand how a font not being available could be caused by my code. Thank you
The image shows a Python traceback indicating an `OSError: cannot open resource`. The error originates from the PIL library while trying to load font files (arial.ttf and DejaVuSans.ttf) using `ImageFont.truetype`. This occurs within the `a8_credit_card_image` function, suggesting an issue with font file accessibility.
The image displays a list of Python function names. These functions, prefixed with "a" and a number, likely represent modules or components related to data processing. Specific functionalities include formatting Markdown, handling dates, contacts, logs, documents, emails, processing credit card images, managing comments, and tracking ticket sales.

image 1505×276 16.1 KB this is a 429 from sanand which is an error from your side. The evaluation already so delayed now has such issues because of which I am getting 1/20. @carlton @Jivraj
The image shows an error log indicating a problem with a running task. It attempts to install "uv" and run a Python script from a GitHub gist.  The process encounters an HTTP 500 Internal Server Error and reports a 429 "Too Many Requests" error when trying to access an OpenAI API endpoint.
does that mean our script is not evaluated?
Hi @Vihaanv07 This was a good spot, we will rerun all the images where string Agent Errro: 429 Client Error.... is present. Thanks and kind regards
Hi @Jayeshbansal There were 12 emails for which we didn’t rerun, we will be fair with grading you and will take care of it.
Screenshot 2025-03-29 at 7.53.20 PM 1440×900 13.2 KB My docker image id is different than the one I submitted “This is the id of the docker image that was evaluated: 10f11a0e0cd6” @carlton @Jivraj @s.anand plz check this
The image shows the output of the `docker images` command. It displays a list of Docker images stored locally, including their repository names, tags, image IDs, creation dates, and sizes. The repositories include projects like "tds-project1," "tesseract," and others. The sizes of the images range from 244MB to 1.75GB, with some images being created years ago.
Hi @23F300327 This is what you submitted to us in the gform. 23f3003027@ds.study.iitm.ac.in	mishkat02/automation-agent:latest We will only evaluate this image. Kind regards
@carlton then why is the image id different? in the docker hub as well as my local terminal the image id is 07b16dc68225
When we build it after pulling it, it will get a unique identifier that makes sure we will only ever evaluate exactly that version. We pull it from your submission in the form. In other words, if any changes occur to the docker repo, our id will no longer match a newer version of the file. This way we can make sure we are evaluating the right version every time. Your id does not have to match ours. But we can detect changes made to the docker repo through our image id. I hope that is clear. We will do some extra sanity checks before the 1/4/2025 just incase there are any issues. But thanks for asking the question. Kind regards
@carlton @Jivraj @Saransh_Saini My logs show,  ‘exec format error’ and it is due to architecture issue,  image was built on mac. I have updated the google form regarding the architecture. Please rerun my image. Thanks
Jivraj: Docker Image Architecture Issue Report If your Docker image was run on the wrong architecture, please fill out this form: Submit Report Just fill the google form, we are rerunning such images.
Error: Failed to process image URL 'https://avatars.discourse-cdn.com/v4/letter/j/b9bd4f/48.png' after 5 retries. Last error: 451 Client Error:  for url: https://avatars.discourse-cdn.com/v4/letter/j/b9bd4f/48.png
Greetings, Sir, I would like to bring to your notice a problem with my original submission of the Docker container. During evaluation, a binary incompatibility between pandas and numpy caused the container to fail. To my surprise, the same versions ( pandas==2.0.3 and numpy==1.24.3 ) were working fine while developing on my local machine. I also tested it with the same Dockerfile on both Linux and Windows platforms using these versions, and it was functioning correctly before pushing and submitting it. I checked the other day after pulling the Docker image from Docker Hub following the submission, and it worked at that time as well. To resolve this issue, I adjusted the Dockerfile to explicitly fix these versions, rebuilt the container, and conducted further testing locally. The application now correctly initializes on port 8000 and returns expected responses within the required 5-minute timeframe. I’ve pushed the updated image to Docker Hub ( santoshsharma003/tds-project-one-1:latest ). Could you please ensure that the latest version of my image is pulled from Docker Hub before rerunning the evaluation? I appreciate your time and effort in reviewing my submission again. Thank you for your assistance!
Hi @carlton , I checked my Docker log file now and realised I missed to push a couple of files to the image. Is there anything I could do now? I have all the required files in my Git repo though. Please help.
