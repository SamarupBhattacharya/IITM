Sir will it answer deployment question? like what will be output link or anything else?
@Jivraj Could we have a tutorial-type session, similar to the one provided for Project 1, just before the deadline?
There are a total of 57 questions in all 5 GAs(18+10+9+10+10). Due to so many different formats of accepting questions and solving them, my main question is: Is the main essence of this project related to deciphering cryptic js code in order to scrape it? Some other doubts are Some questions ask for you to access some hidden divs in the html page and use that for solving (like week 1 q11) Some questions ask you for AIPROXY TOKENs (like week 3 q9) Some questions required manual correction to get correct answers (like week 4 q2) Some questions require file output (like week 2 q2) How do we account for this? @Jivraj @s.anand @carlton
I have few questions just going through the Project 2 problem statement. Are we supposed to use OpenAI api’s or locally/private hosted one? Many of the questions need files or images or audio files as input, same api is expected to handle those also? Can we work in a team and submit the project together? If we are to use locally hosted llm system, our systems are not strong enough to run most of the good ones locally Is it possible to get a TA to collaborate in our project as an observer? awaiting a response. Thank you…
LLM is god, if you dont know how to use llm in your work, you are failed students. unnecessary project statement.
Is it okay if my api only answers the questions which were asked  in my GAs ? @carlton sir @Saransh_Saini
please confirm this query sir @Jivraj because most of them are very hard to make automated.
@s.anand @carlton @Jivraj @Saransh_Saini Dear Sir, I have few questions. It is written in the Tools in Data Science that we can expose the api using vercel (the example given also uses vercel). But I don’t think vercel can handle/allow many operations, some of them are listed below. In GA 1 ques 13 and  GA 2 Ques 7, we have to create github repo, then creating github actions and then retrieve the raw github file url. We can accomplish this using Github CLI gh which we have to install in the vercel instance using apt package manager. But, Vercel does not provide sudo access which is required to install packages. In GA 2 ques 10, we have to use local LLM (Llamafile), will vercel allow that? Also after that, we have to give answer as the ngrok public url for which we have to first install ngrok package. In GA 2 ques 8,  uploading an image to Dockerhub requires docker package installed. In GA 2 ques 6, Deploy a Python API to Vercel in a Vercel instance? Many ques require writing and running FastAPI server to serve data with CORS enabled. Can Vercel allow/do that? And many more Most tasks mentioned above like installing packages etc. requires sudo privilages or may face restrictions set by Vercel. Vercel does not provide sudo access or any form of root access to its hosting environment which is required to perform the above tasks. Many of these task can be done in our local systems (exposing to internet using cloudflare tunnels/ngrok), but we cannot run our systems 24*7 during evaluation. I can see only one option left that is renting a VPS from server providers like digitalocean, gcp, aws etc, which will provide us sudo access and 100% uptime. Also, some ques requires external toolings like In GA1 ques 5, it is written to explicitly use Excel and this will only work in Office 365. In GA1 ques 6, we have to use Devtools to show/find the hidden element in the question. Now, the question parameter in the POST request will be plain text, so how the element can hide there? GA 2 ques 4 and GA 2 ques 5 uses Google Colab specific python libraries like google.colab which can’t be installed locally. How to solve these above questions that require explicit usage of external tools. Also, handling POST request for some questions are not clear like In GA 2 ques 2, we have to compress the image and upload the image as answer. So, now how to response such answer in json object. Should we encode the resultant compressed image as base64 string or Image URL or  Data URI. Some ques have images in them. For those images in GAs, I right clicked and used “Save as” to save the images and then done the required computations. So, now when this question will be sent as POST request, will the image be included as the base64 encoded string in the question parameter of the POST request itself or as an optional file attachment? Another concern is regarding the OpenAI API TOKEN, unlike Project 1, Project 2 does not have an API_TOKEN parameter in the POST request. Hence, the API TOKEN provided from https://aiproxy.sanand.workers.dev will be also used during evaluation. Now, what will happen if our API TOKEN credits gets end during evaluation. The LLM will throw errors then. Please advise what we should do. please clarify Sir.
Can you provide with an evaluation file like we had for Project 1.
Can we have groups for this please? @Jivraj @carlton @s.anand
If you are talking about the parameters of those questions, then it would be better if you make your API capable of working with different parameters.
Well if your API is capable of solving those questions in your GAs with the expected answer, then that’s sufficient validation.
If you are indicating towards working collaboratively then, Yes, we encourage you to collaborate with others and collectively work towards solving this project. Even if you are going for the relatively easiest approach of Function Calling, it would require you to code about 50 functions to solve all your tasks. Which is why it is sensible to work collectively.
Hello Sir, I have a few questions. Would like your thoughts and suggestions over the same. Currently answers that we have entered for GA’s 1 to 4 are not available and only for GA5 its available. It would be helpful for the project (when running the Curl command for each of the question) if the assignments can display the answers we’ve entered as well for verification purposes. The first question of GA1 q1 needs for us to run vs code but when executing it through vercel its not possible because vercel is a serverless environment. In this case, is it okay to manually enter the answer in the code, so when the question is triggered it takes the manual output from the code. Can you provide some clarity as to how the question is supposed to be and structured ? Or should the code be able to handle multiple variants of the question? To address this concern, i tried to implement sentence_transformers using a lightweight model but the vercel application build failed saying that the data is too long and that Vercel serverless function deployment size exceeds the limit of 250 MB. Should i consider deploying elsewhere or change the approach? How do we handle questions pertaining to Devtools - creating input box etc. Thanks and Regards Shalini
What does it mean to solve the question? Everyone is asking that? Do you yourself know what to do and to go about it? Or just pull out something from your hAtSS at the last moment? “and responds with the answer to enter in the assignment.” From my understanding only those questions that are solved with a program and give an answer are to be considered… For example it states in the project that " The response must be a JSON object with a single text (string) field: answer that can be directly entered in the assignment. For example:" If you all still have not responded, then I’m honestly not sure if this is what y’all meant. Last project was not clear to some extent, This time its even more vague. I understand that y’all want to give different projects to help High Order Thinking skills, but if not executed properly, no one actually learns anything and we(I) just end by debugging the project statement code and question with no relevance to the project. If we wanted to do that, I could just go random GitHub repos and solve and create pull requests for a specific bug. Also we end up losing interest thinking most if the course instructors don’t what they are doing. I understand Anand Sir is extremely busy(like really busy lol), but what are the course instructors doing?
The image shows a light-skinned hand emoji. The hand is angled downwards with the index finger pointing directly down. The gesture is commonly used to indicate something below, draw attention downwards, or suggest looking at something specific on the screen.

@Saransh_Saini @carlton Sir is it possible to extend the deadline of this project 2 to Arpil. Because of Quiz2 and Vivas of project should be completed in march only as I am degree potential student. Extending the deadline wont be disadvantage also, project2 will be like ET preparation Please consider this request sir Thanks
I just want to know if you prefer using an existing language model application where we utilize an LLM (Large Language Model), train it, and format the output. For instance, I used the Gemini API key, integrated it with Python, and then formatted the results with the help of Copilot to achieve the desired outputs. Alternatively, do you want us to create a new LLM model and train it with questions from graded assignments? I’m curious about your preference. Additionally, would you like the LLM to provide specific answers regarding computer specifications, or should it give general specifications? For example, in Graded Assignment 1, there is a question about the editor: Visual Studio Code. Your editor is the most important tool in your arsenal; that’s where you’ll spend most of your time, so make sure you’re comfortable with it. Visual Studio Code is, by far, the most popular code editor today. According to the 2024 Stack Overflow Survey, almost 75% of developers use it. We recommend you learn it well. Even if you use another editor, you’ll likely work with others who use VS Code, so having some exposure is beneficial. To get started, you can watch these introductory videos (totaling 35 minutes) from the Visual Studio Docs: Getting Started: Set up and learn the basics of Visual Studio Code (7 min) Code Editing: Learn how to edit and run code in VS Code (3 min) Productivity Tips: Become a VS Code power user with these productivity tips (4 min) Personalize: Personalize VS Code to make it yours with themes (2 min) Extensions: Add features, themes, and more to VS Code with extensions (4 min) Debugging: Get started with debugging in VS Code (6 min) Version Control: Learn how to use Git version control in VS Code (3 min) Customize: Learn how to customize your settings and keyboard shortcuts in VS Code (6 min) AI Editors: Copilot, Cursor Note: AI editors like Cursor, Cody, and GitHub Copilot use LLMs to help you write code faster. These tools are built on top of VS Code and have become standard in every developer’s toolkit. Please make sure to use them. To install and run Visual Studio Code, open your Terminal (or Command Prompt) and type code -s , then press Enter. Copy and paste the entire output below. What is the output of code -s ? The output of code -s cannot be universally answered because it depends on the user’s system and the specific version of VS Code installed. The question requests the output of a command that is unique to each user. As for the part about getting answers from the LLM model, I believe that may require using an AI agent. I am currently searching for a solution for this, and I would like to know your thoughts on it. image 1214×831 34.8 KB
The image shows an IIT Madras Assignment Helper, designed to provide answers to data science assignment questions. A user asks a question by entering a DuckDB SQL query to find post IDs after a specific date with at least 5 useful stars. The tool outputs a SQL query as the answer to retrieve the desired post IDs from a social media table.
can we make this type of solution for above project yantravid-git-main-vicky-kumars-projects-5400c012.vercel.app IIT Madras Assignment Helper
and this is also working with simple question
The image shows a command line interface. A cURL command is used to send a POST request to a Vercel app's API with a "question" parameter set to "what is 2+2?". The server responds with a JSON object containing the answer "4".  The command is executed from the directory "D:\Yantravid>".

image 1260×149 8.95 KB
The image shows a command-line interaction where a `curl` command is used to send a POST request to a specified URL. The request includes a "question" parameter asking to download, extract, and manipulate files within a zip archive. The file names are changed by incrementing each digit. The response from the server includes an "answer" key with a long hexadecimal string.
