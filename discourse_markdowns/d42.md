Do we require open_api key like project 1 for this one too ? if yes from where we can get that?
lakshaygarg654: As per the 19th March session, it was mentioned that the files would be the same for everyone, and only the parameters in the questions would vary. However, I have noticed that the files can actually be different. To support this, I’m attaching screenshots of the CSV files for GA5 Q1—one is mine, and the other belongs to a batchmate. mydata 939×401 18.3 KB friend data 938×465 20.5 KB During the session, it was said that uploading files would take time, and the suggested solution was to pre-download the files on the server since they are supposed to be the same. But since the files are not identical for all students, this issue needs to be addressed. The file is just 341kb. it should take less than a second. So you do not have to pre download this file. Only very large ones that are not parameterised you can have a hard copy of. lakshaygarg654: In GA4 Q2 , my task is to retrieve movie information from IMDb for all films with a rating between 3 and 5. I am scraping the correct movie names(for example 6th movie in given image), but the portal is accepting them differently. All movie names are provided in English, but the portal seems to be accepting some titles in other languages—Spanish, Dutch, I believe. Questions that require manual intervention will be graded very liberally. In other words those questions will not have as strict a grading criteria as in the GA portal. lakshaygarg654: In GA4 Q10 , very few students were able to solve the question using LLMs or Python during the assignment. Most of us ended up solving it manually. At that time, @carlton sir had mentioned that the question would be revised. Here is the thread link for reference. How should we handle this question now? Same as above. Kind regards
Certainly! Here's a summary of the image in under 50 words:

The image features a man with dark hair and a light complexion. He is wearing a white shirt and a black blazer. He has a neatly trimmed mustache and a neutral expression. The background is a blurred white. It appears to be a professional headshot.

The image is a data table displaying sales information. It includes columns for TransactionID, Customer Name, Country, Date, Product/Code, Sales (USD), and Cost (USD).  The table has 14 entries showing various customers from different countries purchasing products on specific dates with corresponding sales and cost values.
The image displays a sales transaction table, including TransactionID, Customer Name, Country, Date, Product/Code, Sales, and Cost. The entries reveal various customers from different countries (IND, US, UK, AE, FRA) making purchases of different products, with corresponding sales and cost data displayed in USD.
Here's a 50-word summary of the image:

The image shows a man in a formal setting. He is wearing a white shirt and a dark-colored blazer or suit jacket. His hair is neatly styled, and he has a mustache. The background is a light or neutral color, likely a studio or office environment.

Here's a 50-word description of the image:

The image shows a man in a suit jacket over a white shirt. He has short dark hair and a light mustache. He appears to be looking directly at the camera with a slight smile. The background is a plain, light color, possibly white or light gray. The lighting is even and clear.

the problem is not the url , if we provide the ending digits of osm_id then only we can match it as multiple cities are there in same country but osm_id is unique
image 1613×554 32.9 KB How to parameterise this function? It is really difficult to do this function with other parameter, please help. what is approach other than hardcoding it?
This Python code snippet, intended for Google Colab, accesses a user's email address and expiry year via Google APIs after authentication. It then concatenates the email and year, calculates its SHA256 hash, and extracts the last five characters of the hash, aiming for a 5-character string as the result. The initial prompt is to ensure proper access to Google Colab.

Did you get a solution for the Markdown question? I have the same issue. @Jivraj @carlton @Saransh_Saini image 892×388 18 KB Can we rather do PlainTextResponse for the markdown question?
This report analyzes daily steps tracked via a fitness device. Data was logged in a spreadsheet and analyzed using Python. Thursday showed 10,000 steps, Friday 9,600 and Monday 8,500. The highest step count was recorded on Sunday. Alice averaged 10,500 steps/day and Bob 9,800. The report suggests increasing daily goals and using advanced trackers for improvement.
@Jivraj @carlton @Saransh_Saini Questions Requiring Clarification/Manual Intervention for Evaluation (As Discussed in Tuesday’s Session) Respected TDS Team, As per the discussion during the Tuesday session, and following @Saransh ’s suggestion, I am creating this post to list the questions that may require manual intervention or are facing issues potentially due to portal-side behavior. Kindly verify these points before evaluation. Questions Requiring Manual Intervention / Portal-Side Issue GA3 Q8 Issue: The question doesn’t mention all required queries. Although all mentioned queries were added, the portal seems to check for additional queries not stated, resulting in an incorrect answer flag. GA3 Q9 Issue: This question asks to create an LLM prompt, but upon submission, a pop-up requests the AIPROXY_TOKEN. Clarification needed: How are we supposed to handle token-based inputs for evaluation? GA4 Q2 & Q10 Issue: Previously encountered issues have been resolved. Reference: GA4 Q2 and Q10 resolution Output Formatting (Multiple Questions) Issue: When using plain text, the answer is accepted. However, in JSON format, newline characters (\n) and backslashes are added. Note: As per the project requirement, the output should be in JSON like {“answer”: “result”}. But directly copy-pasting such a result with special characters leads to rejection by the portal. Vercel / Docker Hub / Ngrok Deployment Questions Issue: Some deployment-related questions require a **live-running server, which needs real-time manual deployment using platforms like Vercel or Ngrok. Clarification needed: How is this expected to be evaluated? Deployment-Related Issues (To Be Included in Thursday’s Session) Please include discussion and solutions for the following deployment issues: Platform Capability for GA Tasks Which cloud platform (Azure, DigitalOcean, etc.) can handle all GA tasks reliably? Note: Some platforms have limitations that block certain tasks or token usage. File Upload Example via Platform API Request: Please provide examples for both small and large file uploads using API from a cloud-deployed app. This would help validate deployments for assignment questions involving file input. General Observations on GA1-5 Output Accuracy: Approximately 80% of the questions in GA1-5 return correct output when tested on a local machine. However, about 20% either have portal-side issues or deployment-related problems. Kindly review these points before final evaluation, and let us know if any additional clarification is required from our side.
The image displays a red exclamation point against a solid black background. The exclamation point is a bright, attention-grabbing color, suggesting a warning, alert, or emphasis. Its rounded shape gives it a slightly cartoonish and friendly appearance.

Thanks a lot @23f2005702 , we’ll try to answer these questions in Thursday’s session.
Is their any way to solve this issue. @Jivraj
@carlton ( @Saransh_Saini ) @Jivraj , is it possible to extend the deadline by 2 days April 1st, since we can use the LLM api a little more and Most people(me atleast) have Their OPPEs and its combined syllabus (and the OPPE 1 did not go well, partly due to my inadequacies) , which has much more to cover, since this project involves more involved coding compared to the last project(ideally project one should have taken not more than a day , still messed it up though xD). Asking for extension for 2 days, if possible. Really need it not even want, like need Summary: Please extend Project 2 deadline by 2 days(April 1st), (actually 1 day extension is April 1st)
Hi @23f1002382 , Unfortunately it’s not possible for us to extend the deadline. Project 2 was released almost a month back, and that can be considered ample amount of time to complete the project. I can understand it must be hard to deal with it along with an upcoming OPPE, but this is what it is. Even if you are not able to cover all the 58 questions, try to cover the majority of them, as the evaluation involves sending just 1-3 questions for evals. All the best for your OPPE and your Project 2
The image displays a yellow-toned hand forming the "peace" or "victory" sign. The hand is raised vertically, with the index and middle fingers extended upwards in a V-shape, while the remaining fingers are curled inwards. This symbol is commonly used to express peace, agreement, or triumph.

@21f2000709 @23f2003751 Yes you are absolutely right. I confirmed this with Carlton and Anand sir, and yes you have to send the JSON responses as strings, which will automatically add those backslashes(\). I apologies for causing this confusion, and I hope I was able to clarify it.
Yes, your response seems correct. It should be a single string containing all the markdown.
@Saransh_Saini can you please confirm 5 Qs at random means 5 random Qs from entire 58 Qs or 1 random Q/GA for the evaluation of TDS Project 2.
Hi @21f3001993 You can use the zipfile library to extract and access zip files pretty easily. You can even make it so that you don’t even have to download the sent file either zip/csv/etc, in order to access it. All this will be discussed in Thurday’s [27-03-2025] Live Session. Kindly attend the session if you want a deeper understanding of it.
It can be any 5 questions.
It can be 1-5 random questions from all 58 question. Its not like a random question each from each GA. It’s even possible to get all those 5 questions from one single GA.
For GA 2 Question 10, how do we host an LLM on a free vm with very limited resources?
Ok, thanks. I won’t be able to attend the session live, but will watch the recording. Thanks for offering to discuss this in live session.
just to clarify if the llm is giving the output like this the evaluation script will mark it correct. {
 "answer": "[{\"name\":\"Charlie\",\"age\":16},{\"name\":\"Liam\",\"age\":23},{\"name\":\"Bob\",\"age\":28},{\"name\":\"Grace\",\"age\":36},{\"name\":\"Ivy\",\"age\":44},{\"name\":\"Jack\",\"age\":53},{\"name\":\"David\",\"age\":56},{\"name\":\"Oscar\",\"age\":57},{\"name\":\"Karen\",\"age\":65},{\"name\":\"Frank\",\"age\":67},{\"name\":\"Nora\",\"age\":68},{\"name\":\"Emma\",\"age\":70},{\"name\":\"Paul\",\"age\":88},{\"name\":\"Alice\",\"age\":92},{\"name\":\"Henry\",\"age\":94},{\"name\":\"Mary\",\"age\":97}]"
 } @Jivraj
Yes, it will. Just make sure that doing a json.loads() on this string should give you the desired output.
