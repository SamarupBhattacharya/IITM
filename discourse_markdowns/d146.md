Sir, the folder already exists in that folder besides, I am using OPENAI_API_KEY=$AIPROXY_TOKEN uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py from Anand sir‚Äôs page to run the code in my system
Sir would the belowformat be ok when you evaluate ? image 985√ó211 24.1 KB
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/original/3X/5/8/58c6872accc838dcec5fda23f4290f5e284dde1e.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
But when I use podman i keep getting errror.
Hello, Can anyone please reset my AIProxy limit. I am getting this error, {‚Äúdetail‚Äù:‚ÄúAgent error: 429 Client Error: Too Many Requests for url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions ‚Äù} Thank you.
i am getting unauthorized error in A9 again and again, i have pasted my code if someone can help please look into this. # /// script
# requires-python = ">=3.11"
# dependencies = [
#   "numpy",
#   "httpx",
#   "fastapi",
# ]
# ///


import httpx
import numpy as np
import datetime
import os

from fastapi import HTTPException


now = datetime.datetime.now()

OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"


# async def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
    # """Calculate cosine similarity between two texts."""
    # emb1 = await embed(text1)
    # emb2 = await embed(text2)
    return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))


# async def embed_list(text_list: list[str]) -> list[float]:
async def embed_list(text_list: list[str]) -> list[float]:
    OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
    OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"
    """Get embedding vector for text using OpenAI's API."""
    try:
        async with httpx.AsyncClient() as client:
            # with httpx.AsyncClient() as client:
            response = await client.post(
                # response = httpx.post(
                OPENAI_API_URL,
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                
                json={"model": "text-embedding-3-small", "input": text_list},
            )
        # print(f'{response.json()["data"][0]["embedding"]}')
        emb_list = [emb["embedding"] for emb in response.json()["data"]]
        print(f"Number of embeddings returned = {len(emb_list)}")
        return emb_list

    except KeyError as e:
        print(f"INSIDE EMBED_LIST IN A9. KeyError occurred while querying GPT: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    except Exception as e:
        print(f"INSIDE EMBED_LIST IN A9. General Error while querying gpt: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def most_similar(embeddings):
    # Extract the phrases and their corresponding embeddings
    phrases = list(embeddings.keys())
    emb_values = list(embeddings.values())

    # Initialize variables to track the maximum similarity
    max_similarity = -1  # Start with the smallest possible similarity value
    most_similar_pair = None

    # Compute cosine similarity between each pair of embeddings
    for i in range(len(emb_values)):
        for j in range(i + 1, len(emb_values)):  # Avoid repeating pairs
            similarity = get_similarity_from_embeddings(emb_values[i], emb_values[j])
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_pair = (phrases[i], phrases[j])

    return most_similar_pair


# async def get_similar_comments(input_file_path: str, output_file_path: str):
async def get_similar_comments(input_file_path: str, output_file_path: str):
    print(f"Reading the input file: {input_file_path}")
    with open(input_file_path, "r") as file:
        comments = file.readlines()

    print(f"Embedding the comments")
    # embeddings = await embed_list(comments)
    embeddings = await embed_list(comments)
    embed_dict = dict(zip(comments, embeddings))
    most_similar_pair = most_similar(embed_dict)
    print(f"Most similar comments: {most_similar_pair}")

    with open(output_file_path, "w") as file:
        for comment in most_similar_pair:
            file.write(f"{comment.strip()}\n")
        # file.write(f"Most similar comments: {most_similar_pair}")


if __name__ == "__main__":
    # import asyncio

    input_file_path = "/data/comments.txt"
    output_file_path = "/data/similar_comments.txt"
    # asyncio.run(get_similar_comments(input_file_path, output_file_path))
    get_similar_comments(input_file_path, output_file_path)
@Jivraj @carlton sir can you take my doubt in today‚Äôs session please , i have successfully run docker server but endpoints are not working‚Ä¶ Screenshot 2025-02-13 165912 1917√ó1024 124 KB If anyone have knowledge about this , please help
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/f/3/f3f203d53c41f1d3c7c214f4904ca32579085bea_2_690x368.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
How did u resolve the issue? @JoelJeffrey
I am also facing the same issue. Evaluation Output: HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

üî¥ A9 failed: 'data'

‚ùå A9 FAILED I sense ‚ÄòAuthentication Problem‚Äô happens only with the evaluation script, as the curl requests seems to work fine. INFO:httpx:HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 200 OK"
INFO:     127.0.0.1:60849 - "POST /run?task=%60%2Fdata%2Fcomments.txt%20contains%20a%20list%20of%20comments,%20one%20per%20line.%20Using%20embeddings,%20find%20the%20most%20similar%20pair%20of%20comments%20and%20write%20them%20to%20%2Fdata%2Fcomments-similar.txt,%20one%20per%20line HTTP/1.1" 200 OK Any views? @carlton @Jivraj
@Jivraj @carlton Sir i keep getting this error image 671√ó109 8.64 KB even though i have downloaded the packages globally and tried installing them by making a venv but nothing seems to work please help
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/original/3X/a/c/acf1856ac9b092f16e614440286674227fb05f45.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
what is the base url?
use your api key guys
we are using that only bro, only for A9 it says unauthorized
network mapping or something, even im working that out
Even i am facing the same problem. I am unable to resolve it ,i tried many ways. could anyone please help
2 ways, try command line package installing, or inside venv, try which python,etc and make paths reconcile, or inside venv, uv pip install , if that doesn‚Äôt work, inside venv pip install
thanks , already it work out
@Jivraj @carlton sir please help When I am downloading the data folder after processing datagen.py , it is trying to download in root folder and it is facing permission error . how can we overcome this ? needs sudo permission all the time‚Ä¶ image 1368√ó124 19.9 KB
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/5/2/529a3326ad0a3a4a60a7c95b080336814e487f6c_2_690x62.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
Hello Sir @carlton @Jivraj What are implications on missing the project 1. Due to some personal reasons I wasn‚Äôt able to start any work on my project 1. It seems difficult for me to complete it. Could you please tell what will be the implications of missing it. Will I in anyway be able to cover up and pass in the subject doing future assignments and projects? Thank you PS: This isn‚Äôt any request to extend dates. I accept my fault and respect the dates provided by the team.
Sir I haven‚Äôt initaiated the podman earlier. Now when i try to use podman using the wsl via the code ‚Äúsudo apt install -y podman‚Äù it is asking for the password‚Ä¶ The problem is: I haven‚Äôt set any password for podman earlier. Though it is asking for password but it is not taking any input.(ie I am unable type anything there). what should I am supposed to do‚Ä¶ image 1612√ó359 21.3 KB
Error: Failed to process image URL 'https://europe1.discourse-cdn.com/flex013/uploads/iitm/optimized/3X/d/3/d36db27ac5478d6c2d5fee2e15c56e2068836c20_2_690x153.png' after 5 retries. Last error: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDqHqkYWWr_VlNmsL-SYK4wKl4tPElJmhw
@s.anand @Jivraj I think the evaluation.py test case is broken for A8 because I can manually see more folders and markdown files than the expected case output of A8 evaluation. And also is there any evaluation file for Part B
